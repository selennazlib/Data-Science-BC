# -*- coding: utf-8 -*-
"""PythonforDataScienceandML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C-cyRwWr0rV2AQbsI7eX_Wx-ZjM4HZEB

**NumPy**

NumPy, is a linear algebra library for python. The reason it is important for Data Science with Python is that almopst all of teh libraries in the PyData Ecosystem rely on NumPy as one of their main building blocks.

**NumPy Arrays**
"""

my_list = [1, 2, 3, 4, 5]
import numpy as np
np.array(my_list)

my_mat = [[1,2],[3, 4]]
np.array(my_mat)

# start point - stop point - step
np.arange(0, 10, 2)
# up to but not including to 10

# zeros vector
v = np.zeros(3)
# zeros matrix 
m = np.zeros((4, 2))
print(v)
print('**********')
print(m)

v = np.ones(5)
m = np.ones((3, 4))
print(v)
print('****************')
print(m)

# start point- stop point- space 
np.linspace(0, 5, 10)
# 10 evenly space points from 0 to 5

np.eye(3)

# will create random 1-D array
d1 = np.random.rand(5)
print(d1)
# will create random 2-D array
d2 = np.random.rand(3, 2)
print(d2)

# 0. version
np.random.randn(2, 3)

# random integer
np.random.randint(0, 5, 10)

arr = np.arange(4)
arr.reshape(2, 2)

arr.reshape(4, 1)

arr.max()

# location oh the min value
arr.argmin()

# (4, )
arr.shape
arr = arr.reshape(2, 2)
# (2, 2)
arr.shape

"""**NumPy indexing and selection**"""

arr = np.arange(15)
# array[start point : stop point : step]
arr[:8:2]

arr[8:]

slice_of_arr = arr[:8]
slice_of_arr[:]

slice_of_arr[:] = 2
slice_of_arr

# also the original array has changed
arr

# the data is not 'automatically' copied
copy_arr = arr.copy()
copy_arr

copy_arr[:] = 3
print(copy_arr)
print(arr)

arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
arr_2d

# arr_2d[0, 1] = arr_2d[0][1]
print(arr_2d[0, 1])
print(arr_2d[0][1])

arr_2d[:2, 1:]

arr_2d[:1,0:]

arr = np.arange(0, 15)
bool_arr = arr > 5
# conditionally select the elements 
print(arr[bool_arr])
# or
print(arr[arr > 5])

arr_2d = np.arange(50).reshape(5, 10)
arr_2d

# for rows from 1 to 4; for columns from 3 to 2 (index)
arr_2d[1:4, 3:5]

# numpy operations
new_arr = np.arange(0, 11)

new_arr * new_arr

new_arr + new_arr

new_arr - 5

new_arr - new_arr
new_arr / new_arr

"""NumPy Exercises"""

# create an array of 10 zeros and 10 ones
print(np.zeros(10))
print(np.ones(10))
# create an array of 10 fives
print(np.ones(10) * 5)
# create an array of the integers from 10 to 50
print(np.arange(10, 51))
# create an array of all even integers from 10 to 50
print(np.arange(10, 51, 2))
# create a 3x3 identity matrix
print(np.eye(3, 3))
# use numpy to generate a random number between 0 and 1
print(np.random.uniform(0, 1))
# create an array of 20 lienarly spaced points between 0 and 1
print(np.linspace(0, 1, 20))

# numpy indexing and selection
mat = np.arange(1, 26).reshape(5, 5)
mat

mat[2:5, 1:5]

mat[3:4, 4:5]

mat[0:3, 1:2]

mat[3:5,:]

print(np.sum(mat))

print(np.std(mat))

# sum of the all columns in mat
sum(mat)

"""**Pandas**

Pandas is an open source library built on top of NumPy.

It allows for fast analysis and data cleaning and preparation.

**Series**
"""

import pandas as pd
cities = ['Eskişehir', 'İstanbul', 'İzmir', 'Ankara']
plaque = np.array([26, 34, 35, 6])
m_dict = {'Eskişehir':26, 'İstanbul':34, 'İzmir':35, 'Ankara':6}
pd.Series(data=plaque, index=cities)

pd.Series(m_dict)

pd.Series([sum, list, max])

ser1 = pd.Series([1, 2, 3], ['USA', 'Italy', 'Poland'])
ser2 = pd.Series([1, 2, 4], ['USA', 'Italy', 'Turkey'])
ser3 = ser1 + ser2
ser3

"""**DataFrames**"""

df = pd.DataFrame(np.random.randn(5, 4), ['Nazlı', 'Selen', 'Fatma', 'Bob', 'Alex'], ['X', 'Y', 'Z', 'W'])
df

df['Y'][0]

type(df['X'])

type(df)

df[['X', 'Y']]

df['new_column'] = 1
df

df.drop('new_column', axis=1, inplace=True)
df

df.drop('Selen', axis=0)

# selecting rows from df
df.loc[['Selen', 'Bob']]

df.loc[['Selen', 'Nazlı'], ['Z', 'Y']]

# iloc -> index based location
# selen <-> Y
df.iloc[1, 1]

df > 0

df.loc[['Selen', 'Bob']] > 0

df[df.loc[['Selen', 'Bob']] > 0]

# double condition
# python 'and', 'or' operators only work(not works with series) for  True or False so we have to use | or &
# error : df[(df['W'] > 0) or (df['Z'] < 1.5)]
df[(df['W'] > 0) | (df['Z'] < 1.5)]

df.reset_index(inplace=True)
df

surnames = ['Halo', 'Lamb', 'Gamer', 'Love', 'Happy']
df['Surnames'] = surnames
df

df.set_index('Surnames')

# index levels - multiindex
outside = ['G1', 'G1', 'G1', 'G2', 'G2', 'G2']
inside = [1, 2, 3, 1, 2, 3]
hier_index = list(zip(outside, inside))
hier_index = pd.MultiIndex.from_tuples(hier_index)

hier_index

df = pd.DataFrame(np.random.randn(6, 2), hier_index, ['A', 'B'])
df

df.loc['G1'].loc[1]

# name for the indexes
df.index.names = ['Groups', 'Num']
df

# G2 2 B
df.loc['G2'].loc[2]['B']

# G1 3 A
df.loc['G1'].loc[3]['A']

# returns a cross-section (row(s) or column(s)) from the dataframe (multi-level indexing)
df.xs('G1')

df.xs(1, level='Num')

# missing data
d = {'A':[1, np.nan, 3], 'B':[5, np.nan, np.nan], 'C':[8, 6, 2]}
df = pd.DataFrame(d)
df

# default axis=0
df.dropna(axis=1)

df.dropna(thresh=2)

df.fillna('*')

df['A'].fillna(value=df['A'].mean())

# groupby 
data = {'Company':['Goog', 'Goog', 'Fb', 'Fb', 'Msft', 'Msft'],
        'Names' :['Selen', 'Bob', 'Alex', 'Sarah', 'Ben', 'Ken'],
        'Sales':[250, 200, 50, 100, 120, 80]}
df = pd.DataFrame(data)
df

df.groupby('Company').mean().loc['Goog']

df.groupby('Names').min()

df.groupby('Names').describe().transpose()['Selen']

# operations 
data = {'col1': [1, 2, 3, 4],
        'col2': ['abc', 'def', 'ghi', 'klm'],
        'col3': [22, 444, 56, 444]}

df = pd.DataFrame(data)
df

print(df['col3'].unique())
print(df['col3'].nunique())
print(df['col3'].value_counts())

df['col3'].apply(lambda x: x + 2)

df.drop('col1', axis=1)

df.sort_values(by='col3')

# data input and output
"""
CSV
Excel
HTML
SQL
"""
pwd

pd.read_csv('example.csv')

